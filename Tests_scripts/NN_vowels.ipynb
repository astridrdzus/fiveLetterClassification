{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - plotting\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##.-*-coding: utf-8-*---------------------------------------------------------------------------\n",
    "# Facultad de Matemáticas de la Universidad Autónoma de Yucatán\n",
    "#--------------------------------------------------------------------------\n",
    "#\n",
    "# MODULE: Image information extraction\n",
    "# FILE: extractData01.py\n",
    "# USE: Preparing data\n",
    "#\n",
    "#> @author\n",
    "#> Astrid Giselle Rodriguez Us\n",
    "#\n",
    "#  DESCRIPTION:\n",
    "# This script reads images of 128x128 pixels, obtains their value data and saves them\n",
    "# to a txt file.\n",
    "#\n",
    "# REVISION HISTORY:\n",
    "#\n",
    "# 02 April 2019 - Initial Version\n",
    "# -- April 2019 - Final Version\n",
    "# TODO_dd_mmm_yyyy - TODO_describe_appropriate_changes - TODO_name\n",
    "#\n",
    "# Modifications:\n",
    "#03 April 2019 - number of lines at the end of the process\n",
    "#22 April 2019 - resize images to an 25% of the original image\n",
    "#29 April 2019 - Defined functions for modularity purposes\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "\n",
    "global  image_list\n",
    "def extractData(dir, num_img, filename):\n",
    "    image_list = []\n",
    "    for file in range(num_img):                             #Indicate the number of images\n",
    "        img= cv2.imread(dir+str(file+1)+'.png')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    #converts an image from rgb values to grayscale values\n",
    "        #-------------------RESIZE------------------#\n",
    "        #print('Original Dimensions : ', gray.shape)\n",
    "        scale_percent = 25                              # percent of original size\n",
    "        width = int(gray.shape[1] * scale_percent / 100)\n",
    "        height = int(gray.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        # resize image\n",
    "        resized = cv2.resize(gray, dim, interpolation=cv2.INTER_AREA)\n",
    "        #print('Resized Dimensions : ', resized.shape)\n",
    "        #-----------------------------------------------#\n",
    "\n",
    "        data = asarray(resized)                            # convert image to numpy array\n",
    "        #print(data)\n",
    "\n",
    "        unidim = []                                     #save the pixel values to an uniarray list\n",
    "        for i in range(32):\n",
    "            for j in range(32):\n",
    "                unidim.append(data[i][j])\n",
    "        image_list.append(unidim)\n",
    "\n",
    "\n",
    "    #save each image list to a file\n",
    "    f= open(filename,\"w+\")\n",
    "    for i in image_list:\n",
    "        f.write(str(i)+\"\\n\")                            #each image list in a line\n",
    "    f.close()\n",
    "    file = open(filename,\"r\")\n",
    "    print('Number of images: ',len(file.readlines()))                        #conts the total number of lines\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##.-*-coding: utf-8-*---------------------------------------------------------------------------\n",
    "# Facultad de Matemáticas de la Universidad Autónoma de Yucatán\n",
    "#--------------------------------------------------------------------------\n",
    "#\n",
    "# MODULE: Obtaning image information\n",
    "# FILE: getData02.py\n",
    "# USE: Preparing data\n",
    "#\n",
    "#> @author\n",
    "#> Astrid Giselle Rodriguez Us\n",
    "#\n",
    "#  DESCRIPTION:\n",
    "# This script reads a txt file to convert the data into numpy arrays\n",
    "# REVISION HISTORY:\n",
    "#\n",
    "# 02 April 2019 - Initial Version\n",
    "# -- April 2019 - Final Version\n",
    "# TODO_dd_mmm_yyyy - TODO_describe_appropriate_changes - TODO_name\n",
    "#\n",
    "# Modifications:\n",
    "#03 April 2019 - implemented getLabel function\n",
    "#29 April 2019 - linked with extractData01_2.py and implemented\n",
    "#               -getTrainData()\n",
    "#               -getValidationData()\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "from extractData01_2 import *\n",
    "def convert(file, num_i):                         #Read the file of images and converts it\n",
    "    f = open(file,'r')                            #to numpy array\n",
    "    images= []\n",
    "    image_list=[]\n",
    "\n",
    "    for i in range(num_i):                         #Indicate the number of images\n",
    "        l = f.readline()\n",
    "        #print(l)\n",
    "        image_list = l.strip(']\\n[').split(', ')  #Save the line into a list\n",
    "        images.append(image_list)\n",
    "        image_list = []\n",
    "\n",
    "    im_array = np.array(images)                   #Converts the list into a numpy array\n",
    "    #print(im_array.shape)                         #Verify the number of rows an columns\n",
    "\n",
    "    #im_array = im_array.astype(np.int_)           #Converts each string item to an int item\n",
    "    #image_list = map(int, image_list)             # Converts each string item to an int item\n",
    "    return im_array\n",
    "    #print(type(image_list))\n",
    "    #return  image_list\n",
    "\n",
    "def getLabelsTRAIN():\n",
    "    # Fills the array with the vector v, n times\n",
    "    aeiou_label = [[1,0,0,0,0]]*300               #a label\n",
    "    aeiou_label = aeiou_label+[[0,1,0,0,0]]*300   #e label\n",
    "    aeiou_label = aeiou_label+[[0,0,1,0,0]]*300   #i label\n",
    "    aeiou_label = aeiou_label+[[0,0,0,1,0]]*300   #o label\n",
    "    aeiou_label = aeiou_label+[[0,0,0,0,1]]*300   #u label\n",
    "    label_array = np.array(aeiou_label)           #Converts the list into a numpy array\n",
    "    #print(label_array.shape)\n",
    "    return label_array\n",
    "    #return  aeiou_label\n",
    "\n",
    "\n",
    "def getLabelsCV():\n",
    "    # Fills the array with the vector v, n times\n",
    "    aeiou_label = [[1,0,0,0,0]]*100               #a label\n",
    "    aeiou_label = aeiou_label+[[0,1,0,0,0]]*100   #e label\n",
    "    aeiou_label = aeiou_label+[[0,0,1,0,0]]*100   #i label\n",
    "    aeiou_label = aeiou_label+[[0,0,0,1,0]]*100   #o label\n",
    "    aeiou_label = aeiou_label+[[0,0,0,0,1]]*100   #u label\n",
    "    label_array = np.array(aeiou_label)           #Converts the list into a numpy array\n",
    "    #print(label_array.shape)\n",
    "    return label_array\n",
    "    #return  aeiou_label\n",
    "\n",
    "\n",
    "def getTrainData():\n",
    "    #Directory where the images are stored\n",
    "    dir = '/home/asteroid/PycharmProjects/nnVocales/dataset_train/data_train_'\n",
    "    filename = 'datasetAEIOU_TRAIN.txt'\n",
    "    num_img = 1500                                 #number of images in the directory\n",
    "    extractData(dir,num_img,filename)\n",
    "\n",
    "    dataTrain_Array = convert(filename,num_img)\n",
    "    return dataTrain_Array\n",
    "\n",
    "def getValidationData():\n",
    "    #Directory where the images are stored\n",
    "    dir = '/home/asteroid/PycharmProjects/nnVocales/dataset_cross_validation/data_cv_'\n",
    "    filename = 'datasetAEIOU_CV.txt'\n",
    "    num_img = 500                                  #number of images in the directory\n",
    "    extractData(dir,num_img,filename)\n",
    "\n",
    "    dataCV_Array = convert(filename,num_img)\n",
    "    return dataCV_Array\n",
    "\n",
    "def getTestData():\n",
    "    #Directory where the images are stored\n",
    "    dir = '/home/asteroid/PycharmProjects/nnVocales/dataset_test/data_test_'\n",
    "    filename = 'datasetAEIOU_CV.txt'\n",
    "    num_img = 500                                  #number of images in the directory\n",
    "    extractData(dir,num_img,filename)\n",
    "\n",
    "    dataTest_Array = convert(filename,num_img)\n",
    "    return dataTest_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  1500\n",
      "(1500, 1024)\n",
      "(1500, 5)\n",
      "Number of images:  500\n",
      "(500, 1024)\n",
      "(500, 5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f59c29a0c7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "##.-*-coding: utf-8-*---------------------------------------------------------------------------\n",
    "# Facultad de Matemáticas de la Universidad Autónoma de Yucatán\n",
    "#--------------------------------------------------------------------------\n",
    "#\n",
    "# MODULE: Building a model\n",
    "# FILE: model_3.py\n",
    "# USE: Build de Neural Network Arquitecture\n",
    "#\n",
    "#> @author\n",
    "#> Astrid Giselle Rodriguez Us\n",
    "#\n",
    "#  DESCRIPTION:\n",
    "# This script implements a neural network arquitecture using Tensorflow and Keras\n",
    "# 02 April 2019 - Initial Version\n",
    "# -- April 2019 - Final Version\n",
    "# TODO_dd_mmm_yyyy - TODO_describe_appropriate_changes - TODO_name\n",
    "#\n",
    "# Modifications:\n",
    "#22 April 2019 - implemented getLabel function\n",
    "#\n",
    "#--------------------------------------------------------------------------\n",
    "from getData02 import*\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import  matplotlib.pyplot as plt\n",
    "#from plotting import *\n",
    "\n",
    "#Getting input data\n",
    "train_X = getTrainData()                             #input train images\n",
    "print(train_X.shape)\n",
    "train_y = getLabelsTRAIN()                           #corresponding train labels\n",
    "print(train_y.shape)\n",
    "val_X = getValidationData()                          #Cross Validation set\n",
    "print(val_X.shape)\n",
    "val_y = getLabelsCV()\n",
    "print(val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "#Building a simple model\n",
    "\n",
    "model= tf.keras.Sequential()\n",
    "#Adds a densely-connected layer with 1500 units to the model:\n",
    "model.add(layers.Dense(1500, activation='sigmoid'))\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(1500, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "#Add a softmax layer with 5 output units:\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "#Evaluate and predict\n",
    "\n",
    "model.fit(train_X, train_y, epochs=20, batch_size=50)\n",
    "\n",
    "model.evaluate(val_X, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)\n",
    "print(val_X[0].shape)\n",
    "model.evaluate(val_X[0], steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
